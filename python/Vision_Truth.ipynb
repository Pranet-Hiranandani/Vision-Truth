{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Vision Truth.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import os\n",
        "import zipfile\n",
        "import csv\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_hub as hub\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fFFTaqPsNAG_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the dataset\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/Dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/data/')"
      ],
      "metadata": {
        "id": "XiOI8gQiPRG4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase precision of presented data for better side-by-side comparison\n",
        "pd.set_option(\"display.precision\", 8)\n",
        "data_root = ('/content/data/Dataset/')\n",
        "tf.config.optimizer.set_jit(True)\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "TRAINING_DATA_DIR = str(data_root)"
      ],
      "metadata": {
        "id": "LW22J-_8NQVd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Intialise Validation Set\n",
        "datagen_kwargs = dict(rescale=1./255, validation_split=0.10)\n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    subset=\"validation\",\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jb3U7_ZnNYEh",
        "outputId": "6e06dad7-f7ff-48e6-d798-f99c2b719c23"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialise Training Set\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAINING_DATA_DIR,\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    target_size=IMAGE_SHAPE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O84F6ptoNi3f",
        "outputId": "964324e6-f258-4c0e-edf5-cd9038887215"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 90000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Intialise labels\n",
        "for image_batch, label_batch in train_generator:\n",
        "  break\n",
        "image_batch.shape, label_batch.shape\n",
        "print (train_generator.class_indices)\n",
        "\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbMYtLkPNvVy",
        "outputId": "94ea6dd3-1a56-4712-81d5-75ae0b17e787"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'fake': 0, 'real': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "IMAGE_SIZE = 224\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  hub.KerasLayer(\"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
        "                 output_shape=[1280],\n",
        "                 trainable=False,\n",
        "                 ),\n",
        "  tf.keras.layers.Dropout(0.4),\n",
        "  #tf.keras.layers.Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build([None,224,224,3])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_cXketyODKN",
        "outputId": "8b5ed401-cb56-4bd6-a3eb-b556bb2b3f8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 0\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3) #1e-3, 3e-4\n",
        "\n",
        "model.compile(\n",
        "  optimizer=optimizer,\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy']\n",
        "  )"
      ],
      "metadata": {
        "id": "vLcuV6oYONuk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "steps_per_epoch = np.ceil(train_generator.samples/train_generator.batch_size)\n",
        "val_steps_per_epoch = np.ceil(valid_generator.samples/valid_generator.batch_size)\n",
        "\n",
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    validation_data=valid_generator,\n",
        "    steps_per_epoch = steps_per_epoch, )"
      ],
      "metadata": {
        "id": "xviMgFyYOcSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the final loss and accuracy\n",
        "results = model.evaluate(valid_generator)\n",
        "print(\"Final loss: {:.2f}\".format(results[0]))\n",
        "print(\"Final accuracy: {:.2f}%\".format(results[0] * 100))"
      ],
      "metadata": {
        "id": "3DiqqPdUOqK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Oc0ymjYseMk"
      },
      "source": [
        "# Convert to Tflite model for classification on mobile\n",
        "tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "tflite_model = tf_lite_converter.convert()\n",
        "open(\"/content/drive/MyDrive/model.tflite\",\"wb\").write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}